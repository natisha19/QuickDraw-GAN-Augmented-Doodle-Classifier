{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# === QuickDraw classifier + simple DCGAN augmentation (PyTorch) ===\n",
        "# Run this in Google Colab (GPU recommended).\n",
        "# Change CLASSES below to pick the 10 classes you want.\n",
        "\n",
        "# 1) Install / import\n",
        "!pip install --quiet wget ndjson\n",
        "\n",
        "import os, time, math, random, wget, io\n",
        "from urllib.request import urlopen\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.utils as vutils\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "id": "lps90upz4jg9",
        "outputId": "ae07a2d5-68ed-4965-9ead-17beddccf439",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Choose your 10 classes (edit this list if you want others)\n",
        "CLASSES = [\n",
        " \"apple\",\"banana\",\"car\",\"cat\",\"dog\",\"house\",\"tree\",\"bicycle\",\"fish\",\"chair\"\n",
        "]\n",
        "# Save to file for reference (Flask can load this file)\n",
        "os.makedirs('data', exist_ok=True)\n",
        "with open('data/classes.txt','w') as f:\n",
        "    f.write(\"\\n\".join(CLASSES))"
      ],
      "metadata": {
        "id": "F1qTxa2R44-G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Download a modest subset per class (adjust examples_per_class)\n",
        "examples_per_class = 2000   # how many sketches per class to download (reduce if slow)\n",
        "out_dir = Path('data')\n",
        "for cls in CLASSES:\n",
        "    fname = out_dir / f\"{cls}.npy\"\n",
        "    if not fname.exists():\n",
        "        url = f\"https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/{cls}.npy\"\n",
        "        print(\"Downloading\", cls)\n",
        "        wget.download(url, str(fname))\n",
        "    else:\n",
        "        print(cls, \"already downloaded.\")"
      ],
      "metadata": {
        "id": "qfGEb-Yj4-sP",
        "outputId": "e95df979-24db-4641-8a0e-32ef44eda832",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading apple\n",
            "Downloading banana\n",
            "Downloading car\n",
            "Downloading cat\n",
            "Downloading dog\n",
            "Downloading house\n",
            "Downloading tree\n",
            "Downloading bicycle\n",
            "Downloading fish\n",
            "Downloading chair\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Load .npy, sample subset, preprocess\n",
        "def load_class_np(cls, n_examples):\n",
        "    arr = np.load(str(out_dir / f\"{cls}.npy\"))\n",
        "    if n_examples and n_examples < len(arr):\n",
        "        idx = np.random.choice(len(arr), n_examples, replace=False)\n",
        "        arr = arr[idx]\n",
        "    # arr shape: (N, 784), values 0..255; convert to float32 0..1\n",
        "    arr = arr.astype('float32')/255.0\n",
        "    arr = arr.reshape((-1, 1, 28, 28))  # channel-first grayscale\n",
        "    return arr\n",
        "\n",
        "X_list, y_list = [], []\n",
        "for i,cls in enumerate(CLASSES):\n",
        "    arr = load_class_np(cls, examples_per_class)\n",
        "    X_list.append(arr)\n",
        "    y_list.append(np.full((arr.shape[0],), i, dtype=np.int64))\n",
        "\n",
        "X = np.concatenate(X_list, axis=0)\n",
        "y = np.concatenate(y_list, axis=0)\n",
        "print(\"Total images:\", X.shape, \"labels:\", y.shape)\n"
      ],
      "metadata": {
        "id": "1sdPI3kT5LDm",
        "outputId": "889aa36c-f7bf-4206-91a2-f2ee5c28c3d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: (20000, 1, 28, 28) labels: (20000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Train / val split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
        "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape)\n"
      ],
      "metadata": {
        "id": "o1Z_-oY85LGz",
        "outputId": "8ebe3007-ab76-4a9e-80ec-e37037f83cc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (17000, 1, 28, 28) Val: (3000, 1, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) PyTorch Dataset wrapper\n",
        "class QuickDrawDataset(Dataset):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.X[idx]  # shape (1,28,28)\n",
        "        label = int(self.y[idx])\n",
        "        img = torch.from_numpy(img)  # tensor float32\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        # print(f'Index {idx} transformed image shape: {img.shape}')\n",
        "        return img, label\n",
        "\n",
        "# optional augmentation for classifier training\n",
        "train_transform = T.Compose([\n",
        "    T.Resize((28,28)),\n",
        "    # inputs are tensors (C,H,W) in 0..1\n",
        "    T.RandomAffine(degrees=15, translate=(0.08,0.08), shear=8),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    # normalize to (-1,1) for tanh based GAN compatibility\n",
        "    T.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "val_transform = T.Compose([\n",
        "    T.Resize((28,28)),\n",
        "    T.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_ds = QuickDrawDataset(X_train, y_train, transform=train_transform)\n",
        "val_ds = QuickDrawDataset(X_val, y_val, transform=val_transform)\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)"
      ],
      "metadata": {
        "id": "_U28cdLP5LJ7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 7) Define a small CNN classifier\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1,32,3,padding=1), nn.ReLU(), nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(2),  # 14x14\n",
        "            nn.Conv2d(32,64,3,padding=1), nn.ReLU(), nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(2),  # 7x7\n",
        "            nn.Conv2d(64,128,3,padding=1), nn.ReLU(), nn.BatchNorm2d(128),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(128, n_classes)\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        x = self.net(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "clf = SimpleCNN(len(CLASSES)).to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "l2wNB_Sj5LNh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8) Train helper\n",
        "def train_classifier(model, train_loader, val_loader, epochs=6, lr=1e-3):\n",
        "    opt = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    best_val = 0.0\n",
        "    for epoch in range(epochs):\n",
        "        print(\"start epoch\")\n",
        "        model.train()\n",
        "        running=0.0; n=0\n",
        "        for xb,yb in train_loader:\n",
        "            xb,yb = xb.to(device), yb.to(device)\n",
        "            opt.zero_grad()\n",
        "            out = model(xb)\n",
        "            loss = criterion(out, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            running += loss.item()*xb.size(0)\n",
        "            n += xb.size(0)\n",
        "        train_loss = running/n\n",
        "        # val\n",
        "        model.eval()\n",
        "        correct=0; total=0; vloss=0.0\n",
        "        with torch.no_grad():\n",
        "            for xb,yb in val_loader:\n",
        "                xb,yb = xb.to(device), yb.to(device)\n",
        "                out = model(xb)\n",
        "                loss = criterion(out, yb)\n",
        "                vloss += loss.item()*xb.size(0)\n",
        "                preds = out.argmax(dim=1)\n",
        "                correct += (preds==yb).sum().item()\n",
        "                total += xb.size(0)\n",
        "        val_loss = vloss/total\n",
        "        val_acc = correct/total\n",
        "        print(f\"Epoch {epoch+1}/{epochs} train_loss={train_loss:.4f} val_loss={val_loss:.4f} val_acc={val_acc:.4f}\")\n",
        "        if val_acc>best_val:\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'classes': CLASSES,\n",
        "                'input_size': (1,28,28),\n",
        "                'output_size': len(CLASSES),\n",
        "                'timestamp': time.time()\n",
        "            }, 'checkpoint_classifier.pth')\n",
        "            best_val = val_acc\n",
        "    print(\"Training finished. Best val acc:\", best_val)\n"
      ],
      "metadata": {
        "id": "4qCYp3GR5LXu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 9) Define a tiny DCGAN (generator + discriminator) for 28x28 grayscale\n",
        "nz = 64  # latent dim\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz=64, ngf=64):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(nz, ngf*4, 3, 1, 0), # -> (ngf*4,3,3)\n",
        "            nn.BatchNorm2d(ngf*4), nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1), # -> (ngf*2,7,7)\n",
        "            nn.BatchNorm2d(ngf*2), nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1), # -> (ngf,14,14)\n",
        "            nn.BatchNorm2d(ngf), nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf, 1, 4, 2, 1), # -> (1,28,28)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self, z):\n",
        "        return self.main(z)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ndf=64):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, ndf, 4, 2, 1), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf*2, 4, 2, 1), nn.BatchNorm2d(ndf*2), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf*2, ndf*4, 3, 1, 0), nn.BatchNorm2d(ndf*4), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.AdaptiveAvgPool2d(1),  # Fixes feature map size regardless of input size\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, 1, 28, 28)\n",
        "            n_flatten = torch.flatten(self.conv(dummy), 1).shape[1]\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(ndf*4, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.fc[:-2](x)\n",
        "        x = self.fc[-2:](x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "G = Generator(nz=nz, ngf=ngf).to(device)\n",
        "\n",
        "\n",
        "D = Discriminator(ndf=ndf).to(device)\n"
      ],
      "metadata": {
        "id": "oADcvCq25s1F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 10) Train a small GAN for a short number of epochs to generate augmentations\n",
        "def train_gan(G, D, data_loader, epochs=6, lr=2e-4):\n",
        "    print(f\"Starting GAN training for {epochs} epochs\")\n",
        "    criterion = nn.BCELoss()\n",
        "    optD = optim.Adam(D.parameters(), lr=lr, betas=(0.5,0.999))\n",
        "    optG = optim.Adam(G.parameters(), lr=lr, betas=(0.5,0.999))\n",
        "    for epoch in range(epochs):\n",
        "        G.train(); D.train()\n",
        "        for i,(imgs,_) in enumerate(data_loader):\n",
        "            # print(f\"GAN train batch img shape: {imgs.shape}\")\n",
        "            real = imgs.to(device)\n",
        "            bs = real.size(0)\n",
        "            # train D on real\n",
        "            D.zero_grad()\n",
        "            label_real = torch.ones(bs,1, device=device)\n",
        "            out_real = D(real)\n",
        "            lossD_real = criterion(out_real, label_real)\n",
        "            # train D on fake\n",
        "            z = torch.randn(bs, nz, 1, 1, device=device)\n",
        "            fake = G(z)\n",
        "            label_fake = torch.zeros(bs,1, device=device)\n",
        "            out_fake = D(fake.detach())\n",
        "            lossD_fake = criterion(out_fake, label_fake)\n",
        "            lossD = (lossD_real + lossD_fake) * 0.5\n",
        "            lossD.backward()\n",
        "            optD.step()\n",
        "            # train G\n",
        "            G.zero_grad()\n",
        "            label_g = torch.ones(bs,1, device=device) # want D to say real\n",
        "            out_fake_forG = D(fake)\n",
        "            lossG = criterion(out_fake_forG, label_g)\n",
        "            lossG.backward()\n",
        "            optG.step()\n",
        "        print(f\"GAN epoch {epoch+1}/{epochs} done\")\n",
        "    # save generator\n",
        "    torch.save(G.state_dict(), \"generator.pth\")\n",
        "    print(\"Saved generator.pth\")"
      ],
      "metadata": {
        "id": "6zndQGwQ52Uj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 11) Run GAN training on a smaller dataset: use subset of train_ds for GAN\n",
        "gan_subset = torch.utils.data.Subset(train_ds, np.random.choice(len(train_ds), min(2000,len(train_ds)), replace=False))\n",
        "gan_loader = DataLoader(gan_subset, batch_size=128, shuffle=True, num_workers=2)\n",
        "train_gan(G, D, gan_loader, epochs=60)  # small number to get basic shapes\n",
        "\n",
        "# visualize some generated samples\n",
        "G.eval()\n",
        "with torch.no_grad():\n",
        "    z = torch.randn(16, nz,1,1, device=device)\n",
        "    samples = G(z).cpu() * 0.5 + 0.5  # denormalize to 0..1\n",
        "    grid = vutils.make_grid(samples, nrow=4, normalize=False)\n",
        "    plt.figure(figsize=(6,6)); plt.axis('off'); plt.imshow(grid.permute(1,2,0).squeeze(), cmap='gray'); plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "FkSWjzgy6Dpk",
        "outputId": "9cfe7084-5c21-4c89-f90f-cc88b0aaa307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting GAN training for 60 epochs\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 1/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 2/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 3/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 4/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 5/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 6/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 7/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 8/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 9/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 10/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 11/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 12/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 13/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 14/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 15/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 16/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 17/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 18/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 19/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 20/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 21/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 22/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 23/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 24/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 25/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 26/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 27/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 28/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 29/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 30/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 31/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 32/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 33/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 34/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 35/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 36/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 37/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 38/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 39/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 40/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 41/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 42/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 43/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 44/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 45/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 46/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 47/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 48/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 49/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 50/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 51/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 52/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 53/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 54/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 55/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 56/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 57/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 58/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 59/60 done\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([128, 1, 28, 28])\n",
            "GAN train batch img shape: torch.Size([80, 1, 28, 28])\n",
            "GAN epoch 60/60 done\n",
            "Saved generator.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12) Generate synthetic images and append to training set for augmentation\n",
        "def generate_synthetic(G, n_per_class=200):\n",
        "    G.eval()\n",
        "    synth_imgs=[]; synth_labels=[]\n",
        "    with torch.no_grad():\n",
        "        for class_idx in range(len(CLASSES)):\n",
        "            for _ in range(n_per_class):\n",
        "                z = torch.randn(1, nz,1,1, device=device)\n",
        "                out = G(z).cpu().numpy()  # shape (1,1,28,28) values in -1..1\n",
        "                img = (out.squeeze(0).astype('float32') + 1.0)/2.0  # to 0..1\n",
        "                synth_imgs.append(img)\n",
        "                synth_labels.append(class_idx)\n",
        "    return np.array(synth_imgs), np.array(synth_labels)\n",
        "\n",
        "synth_X, synth_y = generate_synthetic(G, n_per_class=100)  # 100 synthetic per class => 1000 for 10 classes\n",
        "print(\"Generated synthetic:\", synth_X.shape, synth_y.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "dQ_2MpxI6IiR",
        "outputId": "88246068-6979-4fb5-ab5d-56f96339c9fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated synthetic: (1000, 1, 24, 24) (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Resize synthetic images if needed\n",
        "if synth_X.shape[2] != 28 or synth_X.shape[3] != 28:\n",
        "    synth_X_resized = F.interpolate(\n",
        "        torch.from_numpy(synth_X), size=(28, 28), mode='bilinear', align_corners=False\n",
        "    ).numpy()\n",
        "else:\n",
        "    synth_X_resized = synth_X\n",
        "\n",
        "# Then use synth_X_resized for concatenation\n",
        "X_train_aug = np.concatenate([X_train, synth_X_resized], axis=0)\n",
        "y_train_aug = np.concatenate([y_train, synth_y], axis=0)\n",
        "print(\"Augmented train size:\", X_train_aug.shape)\n"
      ],
      "metadata": {
        "id": "PzS6Z_F56Mih",
        "outputId": "12d3cced-7ac6-4591-9294-fbc8bc5c3b05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmented train size: (18000, 1, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 14) Train classifier with augmented data\n",
        "# Re-make dataset and loader after augmentation\n",
        "train_ds_aug = QuickDrawDataset(X_train_aug, y_train_aug, transform=train_transform)\n",
        "train_loader_aug = DataLoader(train_ds_aug, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "clf = SimpleCNN(len(CLASSES)).to(device)\n",
        "train_classifier(clf, train_loader_aug, val_loader, epochs=8, lr=1e-3)\n",
        "\n"
      ],
      "metadata": {
        "id": "E3jR0B686QXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a459179b-53a5-40a3-f539-84880cebc4d0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start epoch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8 train_loss=1.3460 val_loss=0.7120 val_acc=0.7600\n",
            "start epoch\n",
            "Epoch 2/8 train_loss=0.6872 val_loss=0.3504 val_acc=0.9020\n",
            "start epoch\n",
            "Epoch 3/8 train_loss=0.5403 val_loss=0.3032 val_acc=0.9100\n",
            "start epoch\n",
            "Epoch 4/8 train_loss=0.4819 val_loss=0.2698 val_acc=0.9220\n",
            "start epoch\n",
            "Epoch 5/8 train_loss=0.4545 val_loss=0.2593 val_acc=0.9260\n",
            "start epoch\n",
            "Epoch 6/8 train_loss=0.4283 val_loss=0.2394 val_acc=0.9260\n",
            "start epoch\n",
            "Epoch 7/8 train_loss=0.4073 val_loss=0.2187 val_acc=0.9323\n",
            "start epoch\n",
            "Epoch 8/8 train_loss=0.3971 val_loss=0.2454 val_acc=0.9260\n",
            "Training finished. Best val acc: 0.9323333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 15) Final: load best checkpoint and show example predictions\n",
        "ckpt = torch.load('checkpoint_classifier.pth', map_location=device)\n",
        "clf.load_state_dict(ckpt['model_state_dict'])\n",
        "clf.eval()\n",
        "print(\"Checkpoint classes:\", ckpt.get('classes'))\n",
        "# helper visualize one val batch\n",
        "xb,yb = next(iter(val_loader))\n",
        "xb = xb.to(device); yb = yb.to(device)\n",
        "with torch.no_grad():\n",
        "    out = clf(xb)\n",
        "    preds = out.argmax(1)\n",
        "print(\"Ground:\", [CLASSES[int(x)] for x in yb[:8].cpu().numpy()])\n",
        "print(\"Preds: \", [CLASSES[int(x)] for x in preds[:8].cpu().numpy()])\n",
        "\n"
      ],
      "metadata": {
        "id": "Zd_cZkPb6TI8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a65e2c87-6aa1-4165-93bf-ec550efb472e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint classes: ['apple', 'banana', 'car', 'cat', 'dog', 'house', 'tree', 'bicycle', 'fish', 'chair']\n",
            "Ground: ['cat', 'house', 'dog', 'cat', 'apple', 'banana', 'banana', 'banana']\n",
            "Preds:  ['cat', 'house', 'dog', 'cat', 'apple', 'banana', 'banana', 'banana']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 16) Save final checkpoint with useful metadata for Flask\n",
        "torch.save({\n",
        "    'model_state_dict': clf.state_dict(),\n",
        "    'classes': CLASSES,\n",
        "    'input_size': (1,28,28),\n",
        "    'output_size': len(CLASSES),\n",
        "    'timestamp': time.time()\n",
        "}, 'checkpoint_classifier.pth')\n",
        "print(\"Saved checkpoint_classifier.pth with classes list.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "VbcrvkXF6VYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c45ea04-05bd-4909-85a5-c97684b57588"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved checkpoint_classifier.pth with classes list.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 17) Flask loading snippet (use this in your run.py)\n",
        "print(\"\"\"\n",
        "==== Flask loading snippet ====\n",
        "import torch\n",
        "ckpt = torch.load('checkpoint_classifier.pth', map_location='cpu')\n",
        "classes = ckpt['classes']\n",
        "model = SimpleCNN(len(classes))\n",
        "model.load_state_dict(ckpt['model_state_dict'])\n",
        "model.eval()\n",
        "# when predicting, apply same preprocessing (normalize to -1..1) and run:\n",
        "# x_tensor = torch.from_numpy(img).unsqueeze(0)  # shape (1,1,28,28)\n",
        "# out = model(x_tensor)\n",
        "# pred = out.argmax(dim=1).item()\n",
        "===============================\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "5I0rfwOG6XGU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}